server:
  retention: 1h

  global:
    evaluation_interval: 30s
    scrape_interval: 30s
    scrape_timeout: 10s

  resources:
    requests:
      cpu: 500m
      memory: 1Gi

  nodeSelector:
    kubernetes.io/os: ${operating_system}

  persistentVolume:
    accessModes:
      - ReadWriteOnce
    enabled: true
    mountPath: /data
    size: 20Gi
    storageClass: gp2

alertmanager:
  enabled: true
  nodeSelector:
    kubernetes.io/os: ${operating_system}

kube-state-metrics:
  enabled: true
  nodeSelector:
    kubernetes.io/os: ${operating_system}
  resources:
    limits:
      cpu: 200m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 512Mi

pushgateway:
  enabled: false
  nodeSelector:
    kubernetes.io/os: ${operating_system}

nodeExporter:
  nodeSelector:
    kubernetes.io/os: ${operating_system}

  resources:
    limits:
      cpu: 200m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 512Mi

alertmanagerFiles:
  alertmanager.yml:
    global: {}
    route: 
      group_by: ['alertname','labels']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 3h
      receiver: slack-alerting

    inhibit_rules:
      - source_matchers: [alertname="OutsideBusinessHours"]        
        target_matchers: [alert_outside_business_hours="false"]

ruleFiles: {}
  
serverFiles:
  alerting_rules.yml: {}
  alerts:
      groups:
          - name: slack-alerting
            rules:

### ARGOCD ###

            - alert: ArgocdServiceNotSynced
              expr: argocd_app_info{sync_status!="Synced"} != 0
              for: 15m
              labels:
                severity: warning
              annotations:
                tittle: ArgoCD service not synced (instance {{ $labels.instance }})
                description: "Service {{ $labels.name }} run by argo is currently not in sync.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: ArgocdServiceUnhealthy
              expr: argocd_app_info{health_status!="Healthy"} != 0
              for: 15m
              labels:
                severity: warning
              annotations:
                tittle: ArgoCD service unhealthy (instance {{ $labels.instance }})
                description: "Service {{ $labels.name }} run by argo is currently not healthy.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

### OutsideBusinessHours ###

            - alert: OutsideBusinessHours
              expr: (day_of_week() == 6 or day_of_week() == 0) or (hour() <= 24 or hour() >= 00)
              for: 1m
              labels:
                alert_outside_business_hours: "false"
              annotations:  
                tittle: Outside Business Hours
                description: "This alert fires during outside business hours. It should be blackholed by Alertmanager"

### Linux ###

            - alert: NodeDown
              expr: up{job="dt-sre-node-exporter"} == 0
              for: 3m
              labels:
                  severity: critical
                  ip: "{{ $labels.instance }}"
                  alert_outside_business_hours: "false"
              annotations:
                  title: Node {{ $labels.instance }} is down
                  description:  "Failed to scrape {{ $labels.job }} on {{ $labels.instance }} for more than 3 minutes. Node seems down."
            
            - alert: NodeDown
              expr: up{job="dt-integracao-node-exporter"} == 0
              for: 3m
              labels:
                  severity: critical
              annotations:
                  title: Node {{ $labels.instance }} is down
                  description:  "Failed to scrape {{ $labels.job }} on {{ $labels.instance }} for more than 3 minutes. Node seems down."

            - alert: NodeDown
              expr: up{job="dt-ingestao-node-exporter"} == 0
              for: 3m
              labels:
                  severity: critical
              annotations:
                  title: Node {{ $labels.instance }} is down
                  description:  "Failed to scrape {{ $labels.job }} on {{ $labels.instance }} for more than 3 minutes. Node seems down."

            - alert: NodeDown
              expr: up{job="dt-rpa-node-exporter"} == 0
              for: 3m
              labels:
                  severity: critical
              annotations:
                  title: Node {{ $labels.instance }} is down
                  description:  "Failed to scrape {{ $labels.job }} on {{ $labels.instance }} for more than 3 minutes. Node seems down."

            - alert: NodeDown
              expr: up{job="dt-webdev-node-exporter"} == 0
              for: 3m
              labels:
                  severity: critical
              annotations:
                  title: Node {{ $labels.instance }} is down
                  description:  "Failed to scrape {{ $labels.job }} on {{ $labels.instance }} for more than 3 minutes. Node seems down."      

            - alert: HostOutOfMemory
              expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
              for: 2m
              labels:
                  job: '{{ $labels.job }}'
                  severity: critical
              annotations:
                  tittle: 'Host out of memory (instance {{ $labels.instance }})'
                  description: "Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
            
            - alert: HostHighCpuLoad
              expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100) > 90
              for: 0m
              labels:
                  severity: critical
              annotations:
                  tittle: Host high CPU load (instance {{ $labels.instance }})
                  description: "CPU load is > 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: HostOutOfDiskSpace
              expr: (node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes <15 and ON (instance, device, mountpoint) node_filesystem_readonly == 0
              for: 2m
              labels:
                  severity: critical
              annotations:
                  tittle: Host out of disk space (instance {{ $labels.instance }})
                  description: "Disk is almost full (< 15% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: HostUnusualDiskReadLatency
              expr: rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0
              for: 2m
              labels:
                  severity: warning
              annotations:
                  title: Host unusual disk read latency (instance {{ $labels.instance }})
                  description: "Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: HostUnusualDiskWriteLatency
              expr: rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 0.1 and rate(node_disk_writes_completed_total[1m]) > 0
              for: 2m
              labels:
                  severity: warning
              annotations:
                  tittle: Host unusual disk write latency (instance {{ $labels.instance }})
                  description: "Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: HostUnusualNetworkThroughputIn
              expr: sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 200
              for: 5m
              labels:
                  severity: warning
              annotations:
                  summary: Host unusual network throughput in (instance {{ $labels.instance }})
                  description: "Host network interfaces are probably receiving too much data (> 200 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: HostUnusualNetworkThroughputOut
              expr: sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 200
              for: 5m
              labels:
                  severity: warning
              annotations:
                  tittle: Host unusual network throughput out (instance {{ $labels.instance }})
                  description: "Host network interfaces are probably sending too much data (> 200 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

### WINDOWS-EXPORTER ###

            - alert: WindowsServerCollectorError
              expr: windows_exporter_collector_success == 0
              for: 0m
              labels:
                  severity: critical
              annotations:
                  tittle: Windows Server collector Error (instance {{ $labels.instance }})
                  description: "Collector {{ $labels.collector }} was not successful\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: WindowsServerCpuUsage
              expr: 100 - (avg by (instance) (rate(windows_cpu_time_total{mode="idle"}[2m])) * 100) > 90
              for: 0m
              labels:
                  severity: critical
              annotations:
                  tittle: Windows Server CPU Usage (instance {{ $labels.instance }})
                  description: "CPU Usage is more than 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
            
            - alert: WindowsServerMemoryUsage
              expr: 100 - ((windows_os_physical_memory_free_bytes / windows_cs_physical_memory_bytes) * 100) > 90
              for: 2m
              labels:
                  severity: critical
              annotations:
                  tittle: Windows Server memory Usage (instance {{ $labels.instance }})
                  description: "Memory usage is more than 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: WindowsServerDiskSpaceUsage
              expr: 100.0 - 100 * ((windows_logical_disk_free_bytes / 1024 / 1024 ) / (windows_logical_disk_size_bytes / 1024 / 1024)) > 85
              for: 2m
              labels:
                  severity: critical
              annotations:
                  tittle: Windows Server disk Space Usage (instance {{ $labels.instance }})
                  description: "Disk usage is more than 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

### Kubernetes ###

            - alert: KubernetesNodeReady
              expr: kube_node_status_condition{condition="Ready",status="true"} == 0
              for: 10m
              labels:
                severity: critical
              annotations:
                tittle: Kubernetes Node ready (instance {{ $labels.instance }})
                description: "Node {{ $labels.node }} has been unready for a long time\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: KubernetesMemoryPressure
              expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
              for: 2m
              labels:
                severity: critical
              annotations:
                  tittle: Kubernetes memory pressure (instance {{ $labels.instance }})
                  description: "{{ $labels.node }} has MemoryPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
            
            - alert: KubernetesDiskPressure
              expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
              for: 2m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes disk pressure (instance {{ $labels.instance }})
                description: "{{ $labels.node }} has DiskPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
            
            - alert: KubernetesJobFailed
              expr: kube_job_status_failed > 0
              for: 0m
              labels:
                severity: warning
              annotations:
                tittle: Kubernetes Job failed (instance {{ $labels.instance }})
                description: "Job {{ $labels.namespace }}/{{ $labels.exported_job }} failed to complete\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: KubernetesPersistentvolumeclaimPending
              expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
              for: 2m
              labels:
                severity: warning
              annotations:
                tittle: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})
                description: "PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
            
            - alert: KubernetesPersistentvolumeError
              expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending", job="kube-state-metrics"} > 0
              for: 0m
              labels:
                severity: critical
              annotations:
                tittle: Kubernetes PersistentVolume error (instance {{ $labels.instance }})
                description: "Persistent volume is in bad state\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
                      
            - alert: KubernetesVolumeOutOfDiskSpace
              expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
              for: 2m
              labels:
                severity: warning
              annotations:
                tittle: Kubernetes Volume out of disk space (instance {{ $labels.instance }})
                description: "Volume is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: KubernetesPodNotHealthy
              expr: sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"}) > 0
              for: 15m
              labels:
                severity: critical
              annotations:
                tittle: Kubernetes Pod not healthy (instance {{ $labels.instance }})
                description: "Pod has been in a non-ready state for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: KubernetesPodCrashLooping
              expr: increase(kube_pod_container_status_restarts_total[1m]) > 3
              for: 2m
              labels:
                severity: warning
              annotations:
                tittle: Kubernetes pod crash looping (instance {{ $labels.instance }})
                description: "Pod {{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            - alert: KubernetesStatefulsetDown
              expr: kube_statefulset_replicas != kube_statefulset_status_replicas_ready > 0
              for: 1m
              labels:
                severity: critical
              annotations:
                summary: Kubernetes StatefulSet down (instance {{ $labels.instance }})
                description: "A StatefulSet went down\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

            
  recording_rules.yml: {}
  rules: {}

  prometheus.yml:
    rule_files:
      - /etc/config/recording_rules.yml
      - /etc/config/alerting_rules.yml
      - /etc/config/rules
      - /etc/config/alerts

    scrape_configs:
      - job_name: prometheus
        honor_labels: true
        static_configs:
          - targets:
            - localhost:9090


      - job_name: 'kubernetes-apiservers'

        kubernetes_sd_configs:
          - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https

      - job_name: 'kubernetes-nodes'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/$1/proxy/metrics

      - job_name: 'kubernetes-nodes-cadvisor'
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          insecure_skip_verify: true
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor

      - job_name: 'kubernetes-service-endpoints'
        honor_labels: true
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape_slow]
            action: drop
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: (.+?)(?::\d+)?;(\d+)
            replacement: $1:$2
          - action: labelmap
            regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: service
          - source_labels: [__meta_kubernetes_pod_node_name]
            action: replace
            target_label: node

      - job_name: 'kubernetes-service-endpoints-slow'
        honor_labels: true
        scrape_interval: 5m
        scrape_timeout: 30s
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape_slow]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
            action: replace
            target_label: __scheme__
            regex: (https?)
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            target_label: __address__
            regex: (.+?)(?::\d+)?;(\d+)
            replacement: $1:$2
          - action: labelmap
            regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: service
          - source_labels: [__meta_kubernetes_pod_node_name]
            action: replace
            target_label: node

      - job_name: 'prometheus-pushgateway'
        honor_labels: true
        kubernetes_sd_configs:
          - role: service
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
            action: keep
            regex: pushgateway

      - job_name: 'kubernetes-services'
        honor_labels: true
        metrics_path: /probe
        params:
          module: [http_2xx]
        kubernetes_sd_configs:
          - role: service
        relabel_configs:
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
            action: keep
            regex: true
          - source_labels: [__address__]
            target_label: __param_target
          - target_label: __address__
            replacement: blackbox
          - source_labels: [__param_target]
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_service_name]
            target_label: service

      - job_name: 'kubernetes-pods'
        honor_labels: true
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape_slow]
            action: drop
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
            action: replace
            regex: (https?)
            target_label: __scheme__
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: (.+?)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod
          - source_labels: [__meta_kubernetes_pod_phase]
            regex: Pending|Succeeded|Failed|Completed
            action: drop

      - job_name: 'kubernetes-pods-slow'
        honor_labels: true
        scrape_interval: 5m
        scrape_timeout: 30s
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape_slow]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
            action: replace
            regex: (https?)
            target_label: __scheme__
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: (.+?)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: pod
          - source_labels: [__meta_kubernetes_pod_phase]
            regex: Pending|Succeeded|Failed|Completed
            action: drop
